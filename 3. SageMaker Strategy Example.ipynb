{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在交易策略中使用深度学习模型进行交易决策\n",
    "\n",
    "在这个 Notebook 中我们将尝试训练一个简单的自定义序贯（Sequential）模型，用于判断是否应该在技术指标出现交易信号的时候进行交易。通常来讲，技术指标是基于数学公式所计算出的指标值。技术指标会随行情变化而变化。技术指标可以更直接地反映股市所处的状态，为交易提供指导。比如说，我们在之前的 BackTrader 策略示例中就以收盘价上穿均线作为开仓条件，收盘价下穿均线作为平仓条件。\n",
    "\n",
    "然而，通过指标发出的买卖信号是一个随机过程，不可能非常准确。很多技术指标容易产生钝化，或发出一些错误的买卖信号。在本示例中，我们将以不同周期的技术指标为基础，通过机器学习模型做进一步的判断。您可以自行对模型进行调优并且观察这样做是否能够改善交易决策。\n",
    "\n",
    "开始之前，先确保环境中有 Python 和 pip。建议您选择 Python 3 (Data Science) 内核完成实验。完成这个实验需要 TensorFlow 框架，需要安装最新版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install backtrader -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install tensorflow keras -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install matplotlib==3.1.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip uninstall -y sagemaker\n",
    "!pip install sagemaker==1.72.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "directory = '/root/sagemaker-backtrader-examples'\n",
    "if directory not in sys.path:\n",
    "    sys.path.append(directory)\n",
    "    \n",
    "output_bucket = 'athena-output-cache' # 之前创建的 Athena 输出桶名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后还需要安装 TA-Lib，以生成训练所需的技术指标数值。我们提供了一个可以用于当前环境的 wheel 文件，可以通过以下命令用 pip 直接安装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install talib-binary -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "import talib as ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用 wheel 文件安装后 import 报错，请解除以下代码的注释，下载源代码并重新编译："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y TA-Lib\n",
    "# !git clone https://github.com/kynging/ta-lib\n",
    "# !cd /root/ta-lib && apt install -y cmake gcc && ./configure --prefix=/usr && make && make install\n",
    "# !pip install TA-Lib\n",
    "# import talib as ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "在这个部分我们将进行数据的准备、训练必要的模型并编写策略的回测脚本，用于稍后在 SageMaker Studio 中运行回测。\n",
    "\n",
    "您可能注意到在本示例的路径下已经有生成的模型可供回测使用。如果时间有限的话，可以跳过此步骤直接运行回测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "在这个演示中，我们将多获取自2010年至今的数据用于模型训练和预测。首先我们 import 必要的依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib as ta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "directory = '/root/sagemaker-backtrader-examples'\n",
    "if directory not in sys.path:\n",
    "    sys.path.append(directory)\n",
    "    \n",
    "output_bucket = 'athena-output-cache' # 之前创建的 Athena 输出桶名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来定义一些必要的路径和名称“”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "\n",
    "aws_default_region = session.boto_session.region_name\n",
    "aws_account_id = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "image_repo_name = 'sagemaker-backtrader-examples'\n",
    "image_tag = '3_strategy'\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com.cn/{}:{}'.format(aws_account_id, aws_default_region, image_repo_name, image_tag)\n",
    "print('镜像：', image)\n",
    "\n",
    "s3_bucket = 'stock-data-demo'\n",
    "model_name = 'model-long-short-predict'\n",
    "base_job_name = model_name\n",
    "print('任务名：', base_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据\n",
    "\n",
    "以下的代码将从 Athena 中调取必要的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import get_query_result\n",
    "\n",
    "database = 'stock-data-demo'\n",
    "table = 'stock_day'\n",
    "fields = 'ticker,tradedate,openprice,closeprice,highestprice,lowestprice,turnovervol,accumadjfactor,isopen'\n",
    "end_date = '2020-4-13'\n",
    "orderby = 'tradedate'\n",
    "limit = '1006'\n",
    "ticker = '600519'\n",
    "\n",
    "query_string = f'''\n",
    "SELECT DISTINCT {fields}\n",
    "FROM \"{database}\".\"{table}\"\n",
    "WHERE ticker='{ticker}'\n",
    "AND tradedate<='{end_date}'\n",
    "AND isopen=True\n",
    "ORDER BY {orderby}\n",
    "DESC\n",
    "LIMIT {limit}\n",
    "'''\n",
    "\n",
    "df = get_query_result(query_string, output_bucket)\n",
    "\n",
    "df['ticker'] = df['ticker'].apply(lambda x: str(x))\n",
    "df['ticker'] = df['ticker'].apply(lambda x: '0'*(6-len(x)) + x)\n",
    "df['openprice'] = df['openprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['closeprice'] = df['closeprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['highestprice'] = df['highestprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['lowestprice'] = df['lowestprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df.drop('isopen', 1, inplace=True)\n",
    "df.drop('accumadjfactor', 1, inplace=True)\n",
    "df.set_index('tradedate', inplace=True)\n",
    "df.sort_index(0, inplace=True)\n",
    "df.rename(columns={'openprice': 'open'}, inplace=True)\n",
    "df.rename(columns={'closeprice': 'close'}, inplace=True)\n",
    "df.rename(columns={'highestprice': 'high'}, inplace=True)\n",
    "df.rename(columns={'lowestprice': 'low'}, inplace=True)\n",
    "df.rename(columns={'turnovervol': 'volume'}, inplace=True)\n",
    "df['openinterest'] = 0 # A股中一般并不考虑 interest 这一概念，先设为零\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = df.index[-1]\n",
    "print('Target stock:', ticker, start_date, '-', end_date)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的代码将通过 TA-Lib 生成技术指标，并总结出在历史数据中技术指标的胜率统计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_count = 15 # \n",
    "repeat_step = 1\n",
    "look_back = repeat_count * repeat_step\n",
    "forward_window = 5\n",
    "\n",
    "profit_margin = 0.02 # 止盈条件为2%\n",
    "stop_loss_margin = 0.01 # 止损条件为1%\n",
    "\n",
    "closePrice = df[\"close\"]\n",
    "\n",
    "## 事先创建 DataFrame 的 header\n",
    "header = [\"tradedate\", \"close\"]\n",
    "for i in range(0, repeat_count):\n",
    "    header.append(\"sma\" + str((i+1) * repeat_step))\n",
    "for i in range(0,repeat_count):\n",
    "    header.append(\"roc\" + str((i+1) * repeat_step))\n",
    "header.append(\"long\")\n",
    "header.append(\"short\")\n",
    "\n",
    "print('header:', header)\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "## 通过 talib 计算出 SMA 和 ROC 值\n",
    "# SMA - 即通常所说的算术平均值\n",
    "inputs = {'close': np.array(closePrice)}\n",
    "sma = [] # 包含15个不同周期的SMA时间序列\n",
    "for i in range(0, repeat_count):\n",
    "    sma.append(ta.SMA(np.array(closePrice), timeperiod=(i+1)*repeat_step + 1))\n",
    "# ROC - Rate of change : ((price/prevPrice)-1)*100\n",
    "roc = [] # 包含15个不同周期的ROC时间序列\n",
    "for i in range(0, repeat_count):\n",
    "    roc.append(ta.ROC(np.array(closePrice), timeperiod=(i+1)*repeat_step + 1))\n",
    "\n",
    "## 筛选出触发止盈止损的交易日\n",
    "long_count = 0 # 触发止盈次数\n",
    "short_count = 0 # 触发止损次数\n",
    "n_count = 0 #\n",
    "n = 0\n",
    "for idx in df.index:\n",
    "    if n < len(df) - forward_window - 1:\n",
    "        idx_0 = idx\n",
    "        close_price = df.loc[idx, 'close']\n",
    "        temp = []\n",
    "        temp.append(idx)\n",
    "        \n",
    "        temp2 = []\n",
    "        temp2.append(close_price)\n",
    "\n",
    "        # sma\n",
    "        for i in range(0, repeat_count):\n",
    "            if np.isnan(sma[i][n]):\n",
    "                temp2.append(close_price)\n",
    "            else:\n",
    "                temp2.append(sma[i][n])\n",
    "\n",
    "        min_value = min(temp2)\n",
    "        max_value = max(temp2)\n",
    "        for i in temp2:\n",
    "            if max_value == min_value:\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append((i - min_value) / (max_value - min_value))\n",
    "\n",
    "        # roc\n",
    "        for i in range(0, repeat_count):\n",
    "            if np.isnan(roc[i][n]):\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append(roc[i][n])\n",
    "\n",
    "        rClose = closePrice[(n+1):min(len(df)-1, n+1+forward_window)].values.tolist()\n",
    "        min_value = min(rClose)\n",
    "        max_value = max(rClose)\n",
    "        \n",
    "        # 止盈条件\n",
    "        if max_value >= close_price * (1+profit_margin) and min_value >= close_price * (1-stop_loss_margin):\n",
    "            long_count += 1\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        # 止损条件\n",
    "        if min_value <= close_price * (1-stop_loss_margin) and max_value <= close_price * (1+profit_margin):\n",
    "            short_count += 1\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "        \n",
    "        data.append(temp)\n",
    "        n += 1\n",
    "\n",
    "print(\"止盈：%s, 止损：%s\" % (long_count,short_count))\n",
    "df2 = pd.DataFrame(data, columns=header)\n",
    "df2.set_index('tradedate', inplace=True)\n",
    "print('tradedate:', df2.index[0], '-', df2.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '{}/input/data/training'.format(image_tag)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清注意这些数据集共 1000 个交易日。您可能注意单纯按照技术指标交易产生的交易结果并不理想。\n",
    "\n",
    "接下来我们对数据集进行简单的拆分，分为训练集和测试集两部分，并将数据上传到默认的 S3 路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '{}/input/data/training'.format(image_tag)\n",
    "key_prefix = '{}/{}'.format(image_repo_name, prefix)\n",
    "\n",
    "df_train = df2.iloc[:int(0.6*len(df2))]\n",
    "print('Training set:', df_train.index[0], '-', df_train.index[-1])\n",
    "df_train.to_csv('{}/{}/data_train.csv'.format(directory, prefix))\n",
    "\n",
    "df_test = df2.iloc[int(0.6*len(df2)):]\n",
    "print('Testing set:', df_test.index[0], '-', df_test.index[-1])\n",
    "df_test.to_csv('{}/{}/data_test.csv'.format(directory, prefix))\n",
    "\n",
    "print('上传数据路径：', '{}/{}'.format(directory, prefix))\n",
    "data_location = session.upload_data(directory+'/'+prefix, key_prefix=key_prefix)\n",
    "print('S3数据路径：', data_location)\n",
    "output_location = data_location[:data_location.find('input')] + 'output'\n",
    "print('输出路径：', output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "以下是我们实现准备的 Sequential 模型训练脚本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {directory}/{image_tag}/model/train\n",
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Optional\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your container.\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = os.path.join(prefix, 'input/data/training/data_train.csv')\n",
    "test_path = os.path.join(prefix, 'input/data/training/data_test.csv')\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "\n",
    "\n",
    "# Process and prepare the data\n",
    "def data_process(df, yLen, b):\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for idx, row in df.iterrows():\n",
    "        row1 = []\n",
    "        r = row[1:len(row)-yLen]\n",
    "        for a in r:\n",
    "            row1.append(a)\n",
    "        x = np.array(row1, dtype=float)\n",
    "        y = np.array(row[len(row)-yLen:], dtype=float)\n",
    "        b = len(x)\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "        \n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)\n",
    "    \n",
    "    return dataX, dataY, b\n",
    "\n",
    "\n",
    "def build_classifier(b, yLen):\n",
    "    \n",
    "    print(\"build_classifier:b=%s,yLen=%s\" % (b, yLen))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(b, input_dim=b, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(b/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(yLen,kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model(dataX, dataY, b, yLen):\n",
    "    \n",
    "    model = build_classifier(b, yLen)\n",
    "    model.fit(dataX, dataY, epochs=100, batch_size=1)\n",
    "    scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "    print(\"Training Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    print('Starting the training.')\n",
    "    \n",
    "    yLen = 2\n",
    "    b = 0\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(input_path)\n",
    "        dataX, dataY, b = data_process(df, yLen, b)\n",
    "        print('b:', b, 'yLen:', yLen)\n",
    "        model = generate_model(dataX, dataY, b, yLen)\n",
    "        model.save(os.path.join(model_path, 'model.h5'))\n",
    "        \n",
    "        print('Training is complete. Model saved.')\n",
    "        \n",
    "        df = pd.read_csv(test_path)\n",
    "        dataX, dataY, b = data_process(df, yLen, b)\n",
    "        print('b:', b, 'yLen:', yLen)\n",
    "        scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "        print(\"Test Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failure\n",
    "        # Reason in the DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs\n",
    "        print(\n",
    "            'Exception during training: ' + str(e) + '\\n' + trc,\n",
    "            file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下的命令将通过 SageMaker SDK 远程调用一台实例进行模型训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sagemaker.estimator.Estimator(\n",
    "    image_name=image,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.xlarge',\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=base_job_name)\n",
    "\n",
    "classifier.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成后的模型由 SageMaker 自动打包并上传至 S3。接下来我们将训练生成的名为 \"model.h5\" 的模型文件解压缩到 model/ 路径下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 S3 中解压出模型文件\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import tarfile\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = session.default_bucket()\n",
    "s3_output_path = classifier.model_data.replace('s3://'+ bucket + '/', '')\n",
    "print('s3路径：', s3_output_path)\n",
    "\n",
    "bytestream = io.BytesIO(s3.get_object(Bucket=bucket, Key=s3_output_path)['Body'].read())\n",
    "compressed_file = tarfile.open(fileobj=bytestream)\n",
    "compressed_file.extractall(path=directory+'/3_strategy/')\n",
    "print('解压缩路径：', directory+'/3_strategy/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编写回测任务\n",
    "\n",
    "接下来我们将定义运行回测任务所需的超参和代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义超参\n",
    "\n",
    "这个算法中包含几个重要的参数：\n",
    "  - long_threshold：当模型预测止盈概率超过此数值时做多 (0 到 1 之间的小数)。\n",
    "  - short_threshold：当模型预测止损概率超过此数值时做空 (0 到 1 之间的小数)。因为 A 股不允许做空，设为 1 时策略就不会做空。\n",
    "  - profit_target_pct：止盈条件（百分比）。请注意这个数值应该和训练中定义的 profit_margin 参数保持一致。\n",
    "  - stop_target_pct：止损条件（百分比）。请注意这个数值应该和训练中定义的 stop_loss_margin 参数保持一致。\n",
    "  - size：每次交易的股数。请注意股票的市场价格往往从几元到上千元不等，对不同的股票可能需要调整 size 参数或者调整回测初始的资金量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {directory}/{image_tag}/input/config/hyperparameters.json\n",
    "{ \n",
    "    \"user\" : \"user\",\n",
    "    \"long_threshold\" : \"0.5\",\n",
    "    \"short_threshold\" : \"1\",\n",
    "    \"profit_target_pct\" : \"2.00\",\n",
    "    \"stop_target_pct\" : \"1.00\",\n",
    "    \"size\" : \"60\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行回测\n",
    "\n",
    "### 调取回测数据\n",
    "\n",
    "用于调取的数据集中通常不包含训练数据。您可以确认回测数据集的范围是和 testing 数据集基本一致的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import get_query_result\n",
    "\n",
    "database = 'stock-data-demo'\n",
    "table = 'stock_day'\n",
    "fields = 'ticker,tradedate,openprice,closeprice,highestprice,lowestprice,turnovervol,accumadjfactor,isopen'\n",
    "end_date = '2020-4-13'\n",
    "orderby = 'tradedate'\n",
    "limit = '406'\n",
    "ticker = '600519'\n",
    "\n",
    "query_string = f'''\n",
    "SELECT DISTINCT {fields}\n",
    "FROM \"{database}\".\"{table}\"\n",
    "WHERE ticker='{ticker}'\n",
    "AND tradedate<='{end_date}'\n",
    "AND isopen=True\n",
    "ORDER BY {orderby}\n",
    "DESC\n",
    "LIMIT {limit}\n",
    "'''\n",
    "\n",
    "df = get_query_result(query_string, output_bucket)\n",
    "\n",
    "df['ticker'] = df['ticker'].apply(lambda x: str(x))\n",
    "df['ticker'] = df['ticker'].apply(lambda x: '0'*(6-len(x)) + x)\n",
    "df['openprice'] = df['openprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['closeprice'] = df['closeprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['highestprice'] = df['highestprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df['lowestprice'] = df['lowestprice'] * df['accumadjfactor'] / df['accumadjfactor'].iloc[-1]\n",
    "df.drop('isopen', 1, inplace=True)\n",
    "df.drop('accumadjfactor', 1, inplace=True)\n",
    "df.set_index('tradedate', inplace=True)\n",
    "df.sort_index(0, inplace=True)\n",
    "df.rename(columns={'openprice': 'open'}, inplace=True)\n",
    "df.rename(columns={'closeprice': 'close'}, inplace=True)\n",
    "df.rename(columns={'highestprice': 'high'}, inplace=True)\n",
    "df.rename(columns={'lowestprice': 'low'}, inplace=True)\n",
    "df.rename(columns={'turnovervol': 'volume'}, inplace=True)\n",
    "df['openinterest'] = 0 # A股中一般并不考虑 interest 这一概念，先设为零\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = df.index[-1]\n",
    "print('Target stock:', ticker, start_date, '-', end_date)\n",
    "\n",
    "df.head()\n",
    "df.to_csv('{}/{}/backtest_data.csv'.format(directory, image_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来的脚本包含了运行回测所需的策略代码。该策略将从示例的路径中加载之前训练好的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {directory}/long_short_predict.py\n",
    "\n",
    "import backtrader as bt\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib as ta\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "class MyStrategy(bt.Strategy):\n",
    "    \n",
    "    params=(('printlog', True),)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyStrategy, self).__init__()\n",
    "        \n",
    "        directory = '/root/sagemaker-backtrader-examples'\n",
    "        image_tag = '3_strategy'\n",
    "        \n",
    "        with open(\"{}/{}/input/config/hyperparameters.json\".format(directory, image_tag)) as json_file:\n",
    "            self.config = json.load(json_file)\n",
    "        self.config[\"long_threshold\"]=float(self.config[\"long_threshold\"])\n",
    "        self.config[\"short_threshold\"]=float(self.config[\"short_threshold\"])\n",
    "        self.config[\"size\"]=int(self.config[\"size\"])\n",
    "        self.config[\"profit_target_pct\"]=float(self.config[\"profit_target_pct\"])\n",
    "        self.config[\"stop_target_pct\"]=float(self.config[\"stop_target_pct\"])\n",
    "\n",
    "        self.order=None\n",
    "        self.orderPlaced=False\n",
    "                                \n",
    "        self.model = load_model('{}/{}/model.h5'.format(directory, image_tag))\n",
    "        \n",
    "        # input / indicators\n",
    "        self.repeat_count = 15\n",
    "        self.repeat_step = 1\n",
    "        \n",
    "        self.profitTarget=self.config[\"profit_target_pct\"]/100.0\n",
    "        self.stopTarget=self.config[\"stop_target_pct\"]/100.0\n",
    "        self.size=self.config[\"size\"]\n",
    "    \n",
    "        self.sma=[]\n",
    "        self.roc=[]\n",
    "        for i in range(0, self.repeat_count):\n",
    "            self.sma.append(bt.talib.SMA(self.data, timeperiod=(i+1)*self.repeat_step + 1, plot=False))\n",
    "            self.roc.append(bt.talib.ROC(self.data, timeperiod=(i+1)*self.repeat_step + 1, plot=False))\n",
    "        \n",
    "    def next(self):\n",
    "        super(MyStrategy, self).next()\n",
    "        \n",
    "        idx_0 = self.datas[0].datetime.datetime(0)\n",
    "        close_price = self.datas[0].close\n",
    "        temp = []\n",
    "        \n",
    "        temp2 = []\n",
    "        temp2.append(close_price)\n",
    "\n",
    "        ## sma\n",
    "        for i in range(0, self.repeat_count):\n",
    "            if math.isnan(self.sma[i][0]):\n",
    "                temp2.append(close_price)\n",
    "            else:\n",
    "                temp2.append(self.sma[i][0])\n",
    "\n",
    "        min_value = min(temp2)\n",
    "        max_value = max(temp2)\n",
    "        for i in temp2:\n",
    "            if max_value == min_value:\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append((i - min_value) / (max_value - min_value))\n",
    "\n",
    "        ## roc\n",
    "        for i in range(0, self.repeat_count):\n",
    "            if math.isnan(self.roc[i][0]):\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append(self.roc[i][0])\n",
    "        \n",
    "        ## dataX\n",
    "        dataX = np.array([np.array(temp)])\n",
    "\n",
    "        ## dataY\n",
    "        dataY = self.model.predict(dataX)\n",
    "        \n",
    "#         print(len(dataX[0]), len(dataY[0]))\n",
    "        \n",
    "        ## 开仓条件\n",
    "        tLong = dataY[0][0]\n",
    "        tShort = dataY[0][1]\n",
    "        if not self.position:\n",
    "            fLong = (tLong > self.config[\"long_threshold\"]) \n",
    "            fShort = (tShort > self.config[\"short_threshold\"])\n",
    "            if fLong:\n",
    "                self.order = self.buy(size=self.size)\n",
    "                self.limitPrice = close_price + self.profitTarget*close_price\n",
    "                self.stopPrice = close_price - self.stopTarget*close_price\n",
    "            elif fShort:\n",
    "                self.order = self.sell(size=self.size)                    \n",
    "                self.limitPrice = close_price - self.profitTarget*close_price\n",
    "                self.stopPrice = close_price + self.stopTarget*close_price\n",
    "\n",
    "        ## 平仓逻辑\n",
    "        if self.position:\n",
    "            if self.position.size > 0:\n",
    "                if close_price >= self.limitPrice or close_price <= self.stopPrice:\n",
    "                    self.order = self.sell(size=self.size)\n",
    "            elif self.position.size < 0:\n",
    "                if close_price <= self.limitPrice or close_price >= self.stopPrice:\n",
    "                    self.order = self.buy(size=self.size)\n",
    "                    \n",
    "    ## 日志记录\n",
    "    def log(self, txt, dt=None, doprint=False):\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print(f'{dt.isoformat()},{txt}')\n",
    "\n",
    "    # 记录交易执行情况（可选，默认不输出结果）\n",
    "    def notify_order(self, order):\n",
    "        # 如果 order 为 submitted/accepted，返回空\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            return\n",
    "        # 如果 order 为 buy/sell executed，报告价格结果\n",
    "        if order.status in [order.Completed]: \n",
    "            if order.isbuy():\n",
    "                self.log(f'买入：\\n价格：%.2f,\\\n",
    "                交易金额：-%.2f,\\\n",
    "                手续费：%.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:\n",
    "                self.log(f'卖出:\\n价格：%.2f,\\\n",
    "                交易金额：%.2f,\\\n",
    "                手续费：%.2f' % (order.executed.price, order.executed.price*self.size, order.executed.comm))\n",
    "            self.bar_executed = len(self) \n",
    "\n",
    "        # 如果指令取消/交易失败, 报告结果\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('交易失败')\n",
    "        self.order = None\n",
    "\n",
    "    # 记录交易收益情况（可省略，默认不输出结果）\n",
    "    def notify_trade(self,trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "        self.log(f'策略收益：\\n毛收益 {trade.pnl:.2f}, 净收益 {trade.pnlcomm:.2f}')\n",
    "\n",
    "    # 回测结束后输出结果（可省略，默认输出结果）\n",
    "    def stop(self):\n",
    "        self.log('期末总资金 %.2f' %\n",
    "                 (self.broker.getvalue()), doprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import long_short_predict\n",
    "\n",
    "## 如果对策略进行了修改后想要重新加载策略，则运行以下的代码\n",
    "import importlib\n",
    "importlib.reload(long_short_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行回测任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "import datetime\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import backtrader as bt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建 Cerebro 对象\n",
    "    cerebro = bt.Cerebro()\n",
    "\n",
    "    # 创建 Data Feed\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    start = df.index[0]\n",
    "    end = df.index[-1]\n",
    "    print(start, '-', end)\n",
    "    data = bt.feeds.PandasData(dataname=df, fromdate=start, todate=end)\n",
    "    \n",
    "    # 将 Data Feed 添加至 Cerebro\n",
    "    cerebro.adddata(data)\n",
    "\n",
    "    # 添加策略 Cerebro\n",
    "    cerebro.addstrategy(long_short_predict.MyStrategy)\n",
    "    \n",
    "    # 设置初始资金\n",
    "    cerebro.broker.setcash(100000.0)\n",
    "    # 设置手续费为万二\n",
    "    cerebro.broker.setcommission(commission=0.0002) \n",
    "\n",
    "    # 在开始时 print 初始账户价值\n",
    "    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "\n",
    "    # 运行回测流程\n",
    "    cerebro.run()\n",
    "\n",
    "    # 在结束时 print 最终账户价值\n",
    "    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "cerebro.plot(iplot=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:cn-northwest-1:390780980154:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
